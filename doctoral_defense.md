Narrative for doctoral defense
============================================

Doctoral defense
--------
Hello and welcome to my doctoral defense. I am Brendan, a PhD in Design candidate with a co-major in Forestry and Environmental Resources. As part of the NCSU GeoForAll Lab, here in the Center for Geospatial Analytics, I have been collaboratively designing Tangible Landscape with my colleagues - Anna, Vaclav, Helena, and now Payam. Tangible Landscape is a way to intuitively think about geographic space - to model, analyze, design, and study landscapes.

Spatial thinking
----------
Spatial thinking is how we understand the relationship between things in space. It is how we understand where our bodies are, how to move them, where to go. We use it to understand our surroundings - where things are, how big they are, what shape they are.  We use spatial thinking pervasively in everyday life to recognize things, manipulate things, interact with others, and travel.

3D spatial thinking
----------
Higher dimensional spatial thinking – thinking about form, volume, and processes unfolding in time – plays an important role in disciplines like science, technology, engineering, the arts, and math.

3-dimensional spatial thinking is used in geology to understand the structure of the earth, ecology to understand the structure of ecosystems, civil engineering to shape landscapes, architecture to design buildings, urban planning to model cities, and the arts to shape sculpture.

*Props: 3d printed model*

Spatial computation
----------
We use computers to efficiently store and work with large sets of spatial data.

In engineering, design, and the arts we use computer-aided design (CAD) software to interactively, computationally model complex 3D forms.

In scientific computing we use geographic information systems (GIS), geospatial programming, and spatial statistics to mathematically model, analyze, and simulate multidimensional spatial patterns and processes.

Human-computer interaction
----------
Computers, however, can be hard to use.

A few of us use command line interfaces, typing text based commands into a terminal. *Props: keyboard*

Most of use rely on graphical user interfaces,
mousing or fingering our way through dialog boxes. This sort of interaction is especially hard with GIS, which have vast libraries of functions - hidden in nested menus - that are chained together in complex workflows. *Props: mouse & tablet*

Neither the command line or the graphical interface are intuitive ways to work with 3D space.

Natural interaction
----------
Computer scientists have been designing new, easier ways to interact with computers such as Virtual Reality, Augmented Reality, touch interfaces, and tangible interfaces.

With technologies like VR headsets we can see data in full, stereoscopic 3D. With tangible interfaces we can feel and manipulate that data with our bodies...

*Props: Oculus Rift HMD*

Tangible interaction
----------
Tangible interfaces give digital data a physical form. This means we can touch it, feel it, and change it with our bodies. We can use embodied cognition - thinking built upon, grounded in bodily experience - when we tangibly interact with computations. This is the sort of intuitive thinking we use when we sculpt a sculpture or dance.

Tangible interfaces for geospatial modeling
----------
Recent advances in low cost sensors like the Kinect have spurred the development of new tangible interfaces. There are now dozens of tangible interfaces for 3D modeling. Conceptually these couple a physical 3D model with a digital model.

*Props: Kinect*

XenoVision Mark III Dynamic Sand Table
----------
There are actuated pin tables that can automatically transform. An early prototype - the Dynamic Sand Table - used thousands of actuated pins to computationally transform a terrain model.

inFORM
----------
inFORM, a newer actuated pin table from MIT's Media Lab, combines tangible interaction with gesture and object detection.

Urp
----------
There are augmented architectural models that couple physical and digital models of buildings. Urp used tag-based object detection to digitize physical models of buildings
and then augment them projected analyses like cast shadow.

Collaborative Design Platform
----------
The Collaborative Design Platform uses a Kinect depth sensor to digitize building models.

Sandscape and Illuminating Clay
----------
There are augmented sandboxes that couple physical and ditigal model of landscapes. As users sculpt a physical model, the model is scanned and then augmented with computer graphics. Early prototypes included Sandscape and Illuminating Clay.
Illuminating Clay used an expensive laser scanner to 3D scan a clay model of a landscape.

Tangible Geospatial Modeling System
----------
Inspired by Illuminating Clay, we designed the Tangible Geospatial Modeling System - the first tangible interface powered by a full GIS.

Augmented Reality Sandbox
----------
The Augmented Reality Sandbox uses the inexpensive Kinect sensor for real-time 3D scanning.

Augmented REality Sandtable (ARES)
----------
The US Army Research Lab has recently developed their own prototype - ARES.

Tangible Landscape
----------
The Tangible Geospatial Modeling System evolved into Tangible Landscape. It is powered by GRASS GIS - a free, open source GIS.

Etc.
----------
...










...
